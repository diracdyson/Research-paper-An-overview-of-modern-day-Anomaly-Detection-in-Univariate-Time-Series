# -*- coding: utf-8 -*-
"""sklearnAEboosted.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TJ9G1iWTeO1pfe9o0gw93liMNM_za5P6
"""

!pip install scikeras[tensorflow]

import tensorflow as tf
from tensorflow import keras 
import numpy as np
import pandas as pd
import time
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import AdaBoostRegressor
from google.colab import drive

from scikeras.wrappers import KerasClassifier, KerasRegressor

# still debugging this keras wrapper not sure what's going wrong

def amp():
    model = keras.Sequential()
    see= 0 
    model.add(tf.keras.layers.InputLayer(input_shape=(1)) )
    model.add(tf.keras.layers.Dense(6,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=see),
                                                 trainable=True))
    model.add(tf.keras.layers.Dense(4,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=see),
                                                 trainable=True))
    model.add(tf.keras.layers.Dense(2, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=see),
                                                 trainable=True))
    model.add(tf.keras.layers.Dense(1, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=see),
                                                 trainable=True))
    model.add(tf.keras.layers.Dense(2,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=see),
                                                 trainable=True))
    model.add(tf.keras.layers.Dense(4,kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=see),
                                                 trainable=True))
    model.add(tf.keras.layers.Dense(6, kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=see),
                                                 trainable=True))
    model.compile(loss='mse',optimizer ='adam')
    
    return model

drive.mount('drive')
h=pd.read_csv('/content/drive/My Drive/Colab Notebooks/returnsant.csv')['Hedge Fund'].values.reshape(-1, 1)
#h_s = StandardScaler().fit_transform(h.values.reshape( -1,1))
#a= KerasRegressor(build_fn = amp(),epochs= 100,batch_size=20, verbose=0)
# try and inhereti base class

boost = AdaBoostRegressor(a)
#h_s.shape= (0,195,1)
boost.fit(h,h)
pred = boost.predict(h)

import numpy as np
import keras
from keras.layers import Input, Dense
from keras.models import Model

# Load the data
data = h

# Define the encoding and decoding layers
encoding_dim = 32
batch_size =5 
input_layer = Input(shape=(h.shape[1],))
encoded = Dense(encoding_dim, activation='relu')(input_layer)
decoded = Dense(data.shape[1], activation='sigmoid')(encoded)

# Build the autoencoder model
autoencoder = Model(input_layer, decoded)

# Compile the model
autoencoder.compile(optimizer='adadelta', loss='mse')

# Train the autoencoder
autoencoder.fit(data, data, epochs=50, batch_size=batch_size, shuffle=True, validation_data=(data, data))

# Get the encoded and decoded representations
encoder = Model(input_layer, encoded)
encoded_data = encoder.predict(data)
decoded_data = autoencoder.predict(data)
#input_layer2 = Input(shape=(encoding_dim,h.shape[1]))
# Boost the autoencoder by retraining it on the encoded data
boosted_autoencoder = Model(encoder.output, decoded)
boosted_autoencoder.compile(optimizer='adadelta', loss='mse')
boosted_autoencoder.fit(encoded_data, data, epochs=50, batch_size=batch_size, shuffle=True, validation_data=(encoded_data, data))

encoded_data.shape

